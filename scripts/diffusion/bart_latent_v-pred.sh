# multi-objective
# accelerate launch train_text_diffusion.py --vector_conditional --condition_dim 4 --task multi-objective --dataset_name HUBioDataLab/SELFormer-selfies --wandb_name multiobj_positive_data --learning_rate 2e-4 --num_train_steps 8000 --train_batch_size 32 --tx_dim 512 --tx_depth 12 --objective pred_x0 --enc_dec_model zjunlp/MolGen-large --num_samples 322 --self_condition --scale_shift --loss_type l2 --train_schedule cosine --sampling_timesteps 80 --save_and_sample_every 1 --num_dense_connections 3  --optimizer adamw --train_prob_self_cond 0.5 --latent_model_path saved_latent_models/SELFormer-selfies/2024-07-16_01-53-07
# python train_text_diffusion.py --vector_conditional --condition_dim 4 --task multi-objective --dataset_name HUBioDataLab/SELFormer-selfies --wandb_name multiobj_positive_data --learning_rate 2e-4 --num_train_steps 65000 --train_batch_size 32 --tx_dim 512 --tx_depth 12 --objective pred_x0 --enc_dec_model zjunlp/MolGen-large --num_samples 100 --self_condition --scale_shift --loss_type l2 --train_schedule cosine --sampling_timesteps 80 --save_and_sample_every 750 --num_dense_connections 3  --optimizer adamw --train_prob_self_cond 0.5 --latent_model_path saved_latent_models/SELFormer-selfies/2024-07-16_01-53-07
# multi-objective DPO
# python train_text_diffusion.py --vector_conditional --condition_dim 4 --task dpo_training --dataset_name HUBioDataLab/SELFormer-selfies --wandb_name dpo_training --learning_rate 2e-4 --num_train_steps 1000 --train_batch_size 32 --tx_dim 512 --tx_depth 12 --objective pred_x0 --enc_dec_model zjunlp/MolGen-large --num_samples 3 --self_condition --scale_shift --loss_type l2 --train_schedule cosine --sampling_timesteps 80 --save_and_sample_every 200 --num_dense_connections 3  --optimizer adamw --train_prob_self_cond 0.5 --latent_model_path saved_latent_models/SELFormer-selfies/2024-07-16_01-53-07
# # phenotype
python train_text_diffusion.py --vector_conditional --condition_dim 2518 --task phenotype --dataset_name HUBioDataLab/SELFormer-selfies --wandb_name phenotype --learning_rate 2e-4 --num_train_steps 65000 --train_batch_size 32 --tx_dim 512 --tx_depth 12 --objective pred_x0 --enc_dec_model zjunlp/MolGen-large --num_samples 300 --self_condition --scale_shift --loss_type l2 --train_schedule cosine --sampling_timesteps 80 --save_and_sample_every 1000 --num_dense_connections 3 --optimizer adamw --train_prob_self_cond 0.5 --latent_model_path saved_latent_models/SELFormer-selfies/2024-07-16_01-53-07
# # phenotype_clip
# python train_text_diffusion.py --vector_conditional --condition_dim 2048 --task phenotype_clip --dataset_name HUBioDataLab/SELFormer-selfies --wandb_name phenotype_clip --learning_rate 2e-4 --num_train_steps 65000 --train_batch_size 32 --tx_dim 512 --tx_depth 12 --objective pred_x0 --enc_dec_model zjunlp/MolGen-large --num_samples 700 --self_condition --scale_shift --loss_type l2 --train_schedule cosine --sampling_timesteps 80 --save_and_sample_every 1 --num_dense_connections 3  --optimizer adamw --train_prob_self_cond 0.5 --latent_model_path saved_latent_models/SELFormer-selfies/2024-07-16_01-53-07
